{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import gzip\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import pandas as pd\n",
    "from deepl import DeepLCLI\n",
    "import googletrans\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110099e4",
   "metadata": {},
   "source": [
    "## Unzip JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f109cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip_data_path = glob.glob(\"../data/c4/realnewslike/*.gz\")\n",
    "# save_dir = \"./data/c4\"\n",
    "# for gz_file in unzip_data_path:\n",
    "#     with gzip.open(gz_file, 'rb') as f_in:\n",
    "#         file_name = (\".\").join(gz_file.split(\"/\")[-1].split(\".\")[:-1])\n",
    "#         with open(os.path.join(save_dir,file_name), 'wb') as f_out:\n",
    "#             shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.join(save_dir,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27b864",
   "metadata": {},
   "source": [
    "## Merging Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files = glob.glob(\"data/c4_realnewslike/*train*.json\")\n",
    "# valid_files = glob.glob(\"data/c4_realnewslike/*valid*.json\")\n",
    "# len(train_files), len(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df = pd.read_json(valid_files[0], lines=True)\n",
    "\n",
    "# train_df = pd.DataFrame()\n",
    "# for file in tqdm(train_files, desc=\"merge JSON ...\"):\n",
    "#     tmp = pd.read_json(file, lines=True)\n",
    "#     train_df = pd.concat([train_df, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27066298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3c9d5",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/train_total_realnewslike.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(train_df, f)\n",
    "#     f.close()\n",
    "\n",
    "# with open(\"data/valid_total_realnewslike.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(val_df, f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60934dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c68a19",
   "metadata": {},
   "source": [
    "## Translate with DeepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/train_total_realnewslike.pkl\", \"rb\") as f:\n",
    "#     train_df = pickle.load(f)\n",
    "#     f.close()\n",
    "\n",
    "# with open(\"data/valid_total_realnewslike.pkl\", \"rb\") as f:\n",
    "#     valid_df = pickle.load(f)\n",
    "#     f.close()\n",
    "\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d7b4b",
   "metadata": {},
   "source": [
    "## DeepL CLI Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07533fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepl = DeepLCLI(\"en\", \"ko\")\n",
    "# deepl.timeout = 15000\n",
    "# deepl.max_length = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43072e3",
   "metadata": {},
   "source": [
    "## Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e9043",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def deepl_translate(df):\n",
    "    deepl = DeepLCLI(\"en\", \"ko\")\n",
    "    kor = []\n",
    "    for idx in tqdm(range(len(df)), desc=\"Translate ... \"):\n",
    "        if 3000<len(df.iloc[idx,0])<=6000:\n",
    "            tmp = df.iloc[idx,0].split(\"\\n\")\n",
    "\n",
    "            front = (\" \").join(tmp[:len(tmp)//2])\n",
    "            back = (\" \").join(tmp[len(tmp)//2:])\n",
    "\n",
    "            front_tr = deepl.translate(front)\n",
    "            back_tr = deepl.translate(back)\n",
    "\n",
    "            kor.append((front_tr+back_tr).replace(\"\\n\", \" \"))\n",
    "\n",
    "        elif len(df.iloc[idx,0])>6000:\n",
    "            continue\n",
    "        else:\n",
    "            tr = deepl.translate(df.iloc[idx,0])\n",
    "\n",
    "            kor.append(tr.replace(\"\\n\", \" \"))\n",
    "    return kor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_translate(df):\n",
    "    translator = googletrans.Translator()\n",
    "    kor = []\n",
    "    \n",
    "    for idx in tqdm(range(len(df)), desc=\"Translate ... \"):\n",
    "        kor.append((translator.translate(df.iloc[idx,0], src=\"en\", dest=\"ko\").text).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translate(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c16907",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl = glob.glob(\"data/merged/train*.pkl\")\n",
    "valid_pkl = \"data/merged/validation.00000.pkl\"\n",
    "\n",
    "for i in train_pkl:\n",
    "    with open(i, \"rb\") as f:\n",
    "        train_df = pickle.load(f)\n",
    "        \n",
    "    f = open('data/train.txt','a', encoding='utf-8')\n",
    "    for idx in range(len(train_df)):\n",
    "        f.write(train_df.iloc[idx, 0])\n",
    "        f.close()\n",
    "    \n",
    "with open(valid_pkl, \"rb\") as f:\n",
    "    valid_df = pickle.load(f)\n",
    "\n",
    "f = open('data/valid.txt','a', encoding='utf-8')\n",
    "for idx in range(len(valid_df)):\n",
    "    f.write(valid_df.iloc[idx])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ada8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
